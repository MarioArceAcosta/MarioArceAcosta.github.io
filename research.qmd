---
title: "Using Machine Learning to Estimate the Effect of Undocumented Status on Education-Occupation Mismatch for College Graduates"
author: "Dr. Veronica Sovero and Mario Arce Acosta"
date: last-modified
format:
  html:
    toc: true                # Floating Table of Contents
    toc-location: left       # Puts navigation on the left (like a documentation site)
    toc-depth: 3             # Allows jumping to sub-sections
    code-fold: show          # Default to 'show' if you want to emphasize the code, or 'true' to hide it
    code-tools: true         # Adds a "Source Code" button at top right
    code-link: true          # Hyperlinks functions to their R documentation
    df-print: paged          # Makes large tables scrollable/searchable
    number-sections: true    # Adds "1.1, 1.2" structure for rigor
---


# Libraries/Packages

```{r Libraries}
library(dplyr)
library(stargazer)
library(caret)
library(xtable)
library(ROCR)
library(class)
library(caTools)
library(rpart)  ## recursive partitioning
library(vip)
library(gridExtra)
library(ranger)
#library(doParallel)    ## Optional: for faster RF model training

```

# Loading Data

```{r Load raw data}
data_path <- "G:/Shared drives/Undocu Research/Data"
figures_path <- "G:/Shared drives/Undocu Research/Output/Figures"
setwd(data_path)

library(readr)
sipp08_2 <- read_csv("(Step 1 output) Core_TM SIPP 2008 Wave 2.csv")
View(sipp08_2)
```

# SIPP Data Cleaning and Recoding

```{r Data preparation}
sipp08_2 <- sipp08_2 %>%
  mutate(
    undocu_entry = as.factor(ifelse(timstat=="Other", 1, 0)),
    undocu_likely = as.factor(ifelse(timstat=="Other" & eadjust=="No", 1, 0)),
    education = case_when(
      eeducate == "10th Grade"  | eeducate == "11th Grade" | eeducate == "12th grade, no diploma" | eeducate == "1st, 2nd, 3rd, or 4th grade" | eeducate == "5th Or 6th Grade" | eeducate == "7th Or 8th Grade" | eeducate == "9th Grade" | eeducate == "Less Than 1st Grade"~ "No HS diploma",
      eeducate == "Diploma or certificate from a" | eeducate == "High School Graduate - (diploma" ~ "HS diploma",
      eeducate == "Some college, but no degree" ~ "Some college",
      eeducate =="Associate (2-yr) college degree" ~ "Associate's",
      eeducate == "Bachelor's degree (for example:" ~ "Bachelor's",
      eeducate == "Master's degree (For example: MA," ~ "Master's",
      eeducate == "Doctorate degree (for example:" ~ "PhD",
      TRUE ~ "Unknown" # Default case
    ),
    yrsed = case_when(
      eeducate == "10th Grade"~10,
      eeducate == "11th Grade"~11,
      eeducate == "12th grade, no diploma" | eeducate == "Diploma or certificate from a" | eeducate == "High School Graduate - (diploma" | eeducate == "Some college, but no degree" ~12,
      eeducate == "1st, 2nd, 3rd, or 4th grade"~2.5,
      eeducate == "5th Or 6th Grade"~5.5,
      eeducate == "7th Or 8th Grade"~7.5,
      eeducate == "9th Grade"~9,
      eeducate == "Less Than 1st Grade"~0,
      eeducate =="Associate (2-yr) college degree"~14,
      eeducate == "Bachelor's degree (for example:"~16,
      eeducate == "Master's degree (For example: MA,"~17.5,
      eeducate == "Doctorate degree (for example:"~22,
      eeducate == "Professional School degree (for"~16,
      TRUE ~ NA
    ),
    college = as.factor(ifelse(eeducate=="Bachelor's degree (for example:" | eeducate=="Master's degree (For example: MA," | eeducate=="Doctorate degree (for example:", 1, 0)),
    hs_only = as.factor(ifelse(eeducate=="Some college, but no degree" | eeducate== "Associate (2-yr) college degree" | eeducate=="High School Graduate - (diploma" | eeducate=="Diploma or certificate from a", 1, 0)),
    immig_yr = case_when(
      tmoveus == "1961"~1961,
      tmoveus == "1961-1968"~1966,
      tmoveus == "1969-1973"~1971,
      tmoveus == "1974-1978"~1976,
      tmoveus == "1979-1980"~1980,
      tmoveus == "1981-1983"~1982,
      tmoveus == "1984-1985"~1984,
      tmoveus == "1986-1988"~1987,
      tmoveus == "1989-1990"~1989,
      tmoveus == "1991-1992"~1991,
      tmoveus == "1993-1994"~1993,
      tmoveus == "1995-1996"~1995,
      tmoveus == "1997-1998"~1998,
      tmoveus == "1999"~1999,
      tmoveus == "2000"~2000,
      tmoveus == "2001"~2001,
      tmoveus == "2002-2003"~2002,
      tmoveus == "2004"~2004,
      tmoveus == "2005"~2005,
      tmoveus == "2006"~2006,
      tmoveus == "2007"~2007,
      tmoveus == "2008-2009"~2009,
      TRUE ~ 0 # Default case
    ),
    married = as.factor(ifelse(ems=="Married, spouse absent" | ems=="Married, spouse present", 1, 0)),
    english_difficult = as.factor(ifelse(ehowwell=="Not at all" | ehowwell=="Not well", 1, 0)),
    nonfluent = as.factor(ifelse(ehowwell=="Not at all" | ehowwell=="Not well", 1, 0)),
    english_home = as.factor(ifelse(tlang1=="Not in Universe", 1, 0)),
    spanish_hispanic_latino = as.factor(ifelse(eorigin=="Yes", 1, 0)),
    medicaid = as.factor(ifelse(rcutyp57=="Yes, covered", 1, 0)),
    household_size = ehhnumpp,
    race = case_when(
      erace=="Asian alone" ~ "Asian",
      erace=="Black alone" ~ "Black",
      erace=="White alone" ~ "White",
      erace=="Residual" ~ "Other",
      TRUE ~ "Unknown"
    ),
    fem = as.factor(ifelse(esex=="Female", 1, 0)),
    asian = as.factor(ifelse(erace=="Asian alone", 1, 0)),
    black = as.factor(ifelse(erace=="Black alone", 1, 0)),
    white = as.factor(ifelse(erace=="White alone", 1, 0)),
    other_race = as.factor(ifelse(erace=="Residual", 1, 0)),
    employed = as.factor(ifelse(rmesr=="With a job at least 1 but not all" | rmesr=="With a job entire month, absent" | rmesr=="With a job entire month, worked", 1, 0)),
    years_us = rhcalyr - immig_yr,
    citizen = as.factor(ifelse(ecitizen=="Yes", 1, 0)),
    cit_spouse = as.factor(cit_spouse),
    poverty = as.factor(ifelse(thearn<rhpov, 1, 0)),
    armed_forces = as.factor(ifelse(eafnow=="Yes" | eafever=="Yes", 1, 0)),
    health_ins= as.factor(ifelse(rcutyp57=="Yes, covered" | rcutyp58=="Yes, covered" , 1, 0)),
    medicare = as.factor(ifelse(ecrmth=="Yes, covered", 1, 0)),
    social_security = as.factor(ifelse(rcutyp01=="Yes, covered" | rcutyp03=="Yes, covered", 1, 0)),
    central_latino = as.factor(ifelse(tbrstate=="Central America" & eorigin=="Yes", 1, 0)),
    bpl_usa = as.factor(ifelse(ebornus=="Yes", 1, 0)),
    bpl_asia = as.factor(ifelse(tbrstate == "Eastern Asia"| tbrstate == "South Central Asia"| tbrstate == "South East Asia, West Asia,", 1, 0)),
    top_ten_states = as.factor(ifelse(tfipsst=="California" | tfipsst=="Texas" | tfipsst=="Florida" | tfipsst=="New Jersey" | tfipsst=="Illinois" | tfipsst=="New York" | tfipsst=="North Carolina" | tfipsst=="Georgia" | tfipsst=="Washington" | tfipsst=="Arizona", 1, 0))
  )

sipp08_2$bpl_foreign <- as.factor(ifelse(sipp08_2$bpl_usa==1, 0, 1))
sipp08_2$undocu_likely <- replace(sipp08_2$undocu_likely, sipp08_2$immig_yr <= 1961, 0)
sipp08_2$years_us <- ifelse(sipp08_2$years_us == 2008 | sipp08_2$years_us == 2009 | sipp08_2$years_us == -1 , NA, sipp08_2$years_us)
sipp08_2$tage <- replace(sipp08_2$tage, sipp08_2$tage == "Less than 1 full year old", 0)
sipp08_2$age <- as.numeric(sipp08_2$tage)
sipp08_2$undocu_likely <- replace(sipp08_2$undocu_likely, sipp08_2$armed_forces==1 | sipp08_2$social_security==1, 0 )
sipp08_2$undocu_logical <- as.factor(ifelse(sipp08_2$citizen==0 & (sipp08_2$armed_forces==0 | sipp08_2$medicare==0 | sipp08_2$social_security==0), 1, 0))
sipp08_2$id <- seq_len(nrow(sipp08_2))


# Define column sets for different analyses
variable_lists <- list(
  base = c("undocu_likely", "central_latino", "bpl_asia", "medicaid", "age", "fem", 
           "married", "cit_spouse", "nonfluent", "spanish_hispanic_latino", 
           "household_size", "poverty", "asian", "black", "white", "other_race", 
           "employed", "years_us", "yrsed"),
  
  descriptive = c("undocu_likely", "undocu_logical", "bpl_foreign", "medicaid", 
                  "central_latino", "bpl_asia", "age", "fem", "married", "cit_spouse", 
                  "nonfluent", "spanish_hispanic_latino", "household_size", "poverty", 
                  "asian", "black", "white", "other_race", "employed", "years_us", "yrsed")

)
```

# Subsamples
```{r Dataset creation}
# Create analysis datasets
create_datasets <- function(data, variables) {
  datasets <- list()
  
  # Filter for undocu_logical == 1
  undocu_filter <- data[data$undocu_logical == 1, ]
  
  datasets$dTable <- as.data.frame(undocu_filter[, variables$descriptive]) %>%
    mutate_at(vars(-undocu_likely), as.numeric) %>%
    na.omit()
  
  datasets$sample <- as.data.frame(undocu_filter[, variables$base]) %>%
    na.omit()
  
  datasets$knn <- as.data.frame(undocu_filter[, variables$base]) %>%
    mutate_at(vars(-undocu_likely), as.numeric) %>%
    na.omit()
  
  
  # Demographic subsets (college graduates only)
  datasets$noncit <- data[data$citizen == 0 & data$college == 1, ]
  datasets$central_latino <- data[data$central_latino == 1 & data$college == 1, ]
  datasets$spanish_hispanic_latino <- data[data$spanish_hispanic_latino == 1 & data$college == 1, ]
  datasets$top_states <- data[data$top_ten_states == 1 & data$college == 1, ]
  
  return(datasets)
}

# Create all analysis datasets
all_data <- create_datasets(sipp08_2, variable_lists)

setwd("G:/Shared drives/Undocu Research/Data")
write.csv(sipp08_2, "SIPP08_2.csv", row.names = FALSE)
```

# Logistic

```{r Logistic Regression}
levels(all_data$sample$undocu_likely) <- make.names(levels(all_data$sample$undocu_likely))

set.seed(1)
train_index_logistic <- createDataPartition(all_data$sample$undocu_likely, p = 0.7, list = FALSE)
train_logistic <- all_data$sample[train_index_logistic, ]
test_logistic <- all_data$sample[-train_index_logistic, ]

## Create trainControl object
control <- trainControl(
    method = "cv",
    number = 10,  
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    sampling = "up"
)

## Train glm with custom trainControl
logistic_model <- train(undocu_likely ~ age + fem + married + cit_spouse + nonfluent + spanish_hispanic_latino + central_latino + bpl_asia + medicaid + household_size + poverty + asian + black + white + other_race + employed + years_us + yrsed, train_logistic,
               method = "glm",
               trControl = control,
               metric = 'ROC')

p_logistic <- predict(logistic_model, test_logistic)


# Generate confusion matrix
logistic_matrix <- confusionMatrix(p_logistic, test_logistic$undocu_likely, positive = "X1")
print(logistic_matrix)
summary_logistic<-summary(logistic_model)$coefficients[,c(1,4)]
summary_logistic
xtable(summary_logistic, digits=4)

## Metrics for Figure 2 comparison
# Make predictions on test set
logistic.preds = predict(logistic_model, newdata = test_logistic, type = "prob")[, 2]  # Get probabilities for class "1"
# Create prediction object for ROCR
logistic.prediction = prediction(logistic.preds, test_logistic$undocu_likely)

logistic.pr = performance(logistic.prediction,"prec","rec") # Precision-Recall curve
```


# KNN

```{r KNN}
set.seed(1)
levels(all_data$knn$undocu_likely) <- make.names(levels(all_data$knn$undocu_likely))
train_index_knn <- createDataPartition(all_data$knn$undocu_likely, p = 0.7, list = FALSE)
train_knn <- all_data$knn[train_index_knn, ]
test_knn <- all_data$knn[-train_index_knn, ]



knn_model <- train(undocu_likely ~., data = train_knn, method = "knn", 
                       trControl = control, 
                       tuneLength = 10,
                       metric = 'ROC',
                       preProcess = c('center', 'scale'))

knn_model

predict_knn <- predict(knn_model, test_knn)

knn_matrix <- confusionMatrix(predict_knn, test_knn$undocu_likely, positive = "X1")
print(knn_matrix)


## Metrics for Figure 2 comparison
# Make predictions on test set
knn.preds = predict(knn_model, newdata = test_knn, type = "prob")[, 2]  # Get probabilities for class "1"
# Create prediction object for ROCR
knn.prediction = prediction(knn.preds, test_knn$undocu_likely)

knn.pr = performance(knn.prediction,"prec","rec") # Precision-Recall curve
```

-   The number of trees in the forest

-   The number of features to consider at any given split: $m_{try}$

-   The complexity of each tree

-   The sampling scheme

-   The splitting rule to use during tree construction

-   and (2) typically have the largest impact on predictive accuracy and
    should always be tuned. (3) and (4) tend to have marginal impact on
    predictive accuracy but are still worth exploring. They also have
    the ability to influence computational efficiency. (5) tends to have
    the smallest impact on predictive accuracy and is used primarily to
    increase computational efficiency.
    
# RF

```{r Random Forest}
#| label: train-random-forest
#| cache: true
#| warning: false


### You may use the following code to speed up code being ran (Use all cores except one)
# cl <- makePSOCKcluster(detectCores() - 1) 
# registerDoParallel(cl)

levels(all_data$sample$undocu_likely) <- make.names(levels(all_data$sample$undocu_likely))


train_index_rf <- createDataPartition(all_data$sample$undocu_likely, p = 0.7, list = FALSE)
train_rf <- all_data$sample[train_index_rf, ]
test_rf <- all_data$sample[-train_index_rf, ]


train_rf <- train_rf %>%
  select(-undocu_likely, undocu_likely)

#Manual search by create 10 folds and repeat 3 times
#control_rf <- trainControl(method = 'repeatedcv',
                        #number = 10,
                       # repeats = 3,
                        #search = 'grid')

tunegrid <- expand.grid(mtry = c(2,4,8,12),
                      splitrule = c("gini", "extratrees"),
                      min.node.size = 1)

control_up <- trainControl(
    method = "cv",
    number = 10,  
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    sampling = "up",
)


set.seed(1)
rf_model <- train(undocu_likely ~ age + fem + married + cit_spouse + medicaid + nonfluent + spanish_hispanic_latino + central_latino + bpl_asia + household_size + poverty + asian + black + white + other_race + employed + years_us + yrsed,
               data = train_rf,
               method = "ranger",
               trControl = control_up,
               tuneLength = 5,
               importance = "impurity",
               metric = 'ROC')
print(rf_model)
plot(rf_model)

p_rf <- predict(rf_model, test_rf)

rf_matrix <- confusionMatrix(p_rf, test_rf$undocu_likely, positive="X1")
rf_matrix

feature_importance <- vip(rf_model, num_features = 19, bar = FALSE)
grid.arrange(feature_importance, nrow = 1)

all_data$dTable$undocu_logit <- predict(logistic_model, all_data$sample)
all_data$dTable$undocu_knn <- predict(knn_model, all_data$knn)
all_data$dTable$undocu_rf <- predict(rf_model, all_data$sample)
setwd("G:/Shared drives/Undocu Research/Data")
write.csv(all_data$dTable, "SIPP_dTable.csv", row.names = FALSE)


rf_model$finalModel$num.trees

# Access specific parameters
rf_optimal_trees <- rf_model$bestTune$mtry
cat("Optimal mtry:", rf_optimal_trees, "\n")

## Metrics for Figure 2 comparison
# Make predictions on test set
rf.preds = predict(rf_model, newdata = test_rf, type = "prob", n.trees = rf_optimal_trees)[, 2]  # Get probabilities for class "1"
# Create prediction object for ROCR
rf.prediction = prediction(rf.preds, test_rf$undocu_likely)

rf.pr = performance(rf.prediction,"prec","rec") # Precision-Recall curve

# stopCluster(cl) # Optional code part of parallel processing
```

